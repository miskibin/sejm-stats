{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def clean_title(title):\n",
    "    if \"wyrok\" in title.lower():\n",
    "        cleaned = clean_court_ruling(title)\n",
    "    else:\n",
    "        cleaned = clean_regulation(title)\n",
    "    return cleaned if len(cleaned) > 45 else title\n",
    "\n",
    "\n",
    "def clean_court_ruling(title):\n",
    "    \"\"\"Handle court rulings specifically\"\"\"\n",
    "    # Extract court name, date, and case number\n",
    "    court_match = re.match(\n",
    "        r\"^Wyrok\\s+(.*?)\\s+z\\s+dnia\\s+(\\d+\\s+\\w+\\s+\\d{4})\\s*r\\.\\s*sygn\\.*(.*?)$\",\n",
    "        title,\n",
    "        re.IGNORECASE,\n",
    "    )\n",
    "\n",
    "    if court_match:\n",
    "        court = court_match.group(1)\n",
    "        date = court_match.group(2)\n",
    "        case_number = court_match.group(3)\n",
    "        # Format: \"Court ruling - case_number (date)\"\n",
    "        cleaned = f\"Wyrok {court} - {case_number}\"\n",
    "        return cleaned\n",
    "    return title\n",
    "\n",
    "\n",
    "def clean_regulation(title):\n",
    "\n",
    "    # Extract the authority and the rest of the title\n",
    "    match = re.match(\n",
    "        r\"^(?:Rozporządzenie|Obwieszczenie)\\s+(.*?)\\s+z\\s+dnia.*?(?:w sprawie|zmieniające)\",\n",
    "        title,\n",
    "        re.IGNORECASE,\n",
    "    )\n",
    "    authority = match.group(1) if match else \"\"\n",
    "\n",
    "    # Remove the document type, date, and \"w sprawie\" phrases\n",
    "    title = re.sub(r\"^.*?(?:z dnia \\d+\\s+\\w+\\s+\\d{4}\\s*r\\.\\s*)\", \"\", title)\n",
    "    title = re.sub(\n",
    "        r\"(?:zmieniające\\s+rozporządzenie\\s+)?w\\s+sprawie\\s+\", \"dot. \", title\n",
    "    )\n",
    "    title = title.replace(\n",
    "        \"Rzeczypospolitej Polskiej ogłoszenia jednolitego tekstu ustawy\", \"\"\n",
    "    )\n",
    "\n",
    "    # Combine authority with cleaned title\n",
    "    cleaned_title = f\"{authority} {title}\".strip()\n",
    "\n",
    "    # Remove code patterns like (PLH120079)\n",
    "    cleaned_title = re.sub(r\"\\(\\w+\\d+\\)\", \"\", cleaned_title)\n",
    "\n",
    "    # Remove extra whitespace\n",
    "    cleaned_title = re.sub(r\"\\s+\", \" \", cleaned_title).strip()\n",
    "\n",
    "    # Remove specific patterns - now excluding 'Ministra' and 'Marszałka'\n",
    "    patterns_to_remove = [\n",
    "        r\"Prezesa Rady Ministrów\",\n",
    "        r\"Rady Ministrów\",\n",
    "        r\"ogłoszenia jednolitego tekstu\",\n",
    "        r\"zmieniające rozporządzenie\",\n",
    "    ]\n",
    "    for pattern in patterns_to_remove:\n",
    "        cleaned_title = re.sub(pattern, \"\", cleaned_title)\n",
    "\n",
    "    # Final cleanup\n",
    "    cleaned_title = re.sub(r\"\\s+\", \" \", cleaned_title).strip()\n",
    "\n",
    "\n",
    "    return cleaned_title\n",
    "\n",
    "\n",
    "# Test cases including short titles\n",
    "test_cases = [\n",
    "    # Short titles that should be preserved\n",
    "    \"Postanowienie Prezydenta Rzeczypospolitej Polskiej nr 115.7.2023\",\n",
    "    \"Ustawa z dnia 9 marca 2023 r. o cudzoziemcach\",\n",
    "    \"Wyrok Sądu Najwyższego z dnia 15 marca 2023 r.\",\n",
    "    # Regular longer titles that should be cleaned\n",
    "    \"Obwieszczenie Marszałka Sejmu Rzeczypospolitej Polskiej z dnia 11 stycznia 2023 r. w sprawie ogłoszenia jednolitego tekstu ustawy o dodatku osłonowym\",\n",
    "    \"Wyrok Trybunału Konstytucyjnego z dnia 11 stycznia 2024 r. sygn. akt K 23/23\",\n",
    "    \"Rozporządzenie Ministra Zdrowia z dnia 15 lutego 2024 r. w sprawie standardów organizacyjnych (PLH120079)\",\n",
    "    \"Obwieszczenie Marszałka Sejmu Rzeczypospolitej Polskiej z dnia 1 marca 2024 r. w sprawie ogłoszenia jednolitego tekstu ustawy o podatku dochodowym\",\n",
    "    \"Rozporządzenie Ministra Infrastruktury z dnia 11 września 2024 r. w sprawie zaliczenia dróg do kategorii dróg krajowych\",\n",
    "    \"Rozporządzenie Rady Ministrów z dnia 16 września 2024 r. w sprawie wprowadzenia stanu klęski żywiołowej na obszarze części województwa dolnośląskiego, opolskiego oraz śląskiego\",\n",
    "    'Obwieszczenie Ministra Rolnictwa i Rozwoju Wsi z dnia 20 sierpnia 2024 r. w sprawie ogłoszenia jednolitego tekstu rozporządzenia Ministra Rolnictwa i Rozwoju Wsi w sprawie szczegółowych warunków i trybu przyznawania oraz wypłaty pomocy finansowej na operacje typu \"Modernizacja gospodarstw rolnych\" w ramach poddziałania \"Wsparcie inwestycji w gospodarstwach rolnych\" objętego Programem Rozwoju Obszarów Wiejskich na lata 2014-2020',\n",
    "]\n",
    "\n",
    "# Run tests\n",
    "for case in test_cases:\n",
    "    print(f\"\\nInput  ({len(case)} chars): {case}\")\n",
    "    cleaned = clean_title(case)\n",
    "    print(f\"Output ({len(cleaned)} chars): {cleaned}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_title(\"Rozporządzenie Rady Ministrów z dnia 7 sierpnia 2023 r. zmieniające rozporządzenie w sprawie Krajowej Tablicy Przeznaczeń Częstotliwości\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load documents from `acts.csv` `\n",
    "import pandas as pd\n",
    "\n",
    "acts = pd.read_csv(\"acts.csv\")\n",
    "acts['title'] = acts['title'].apply(clean_title)\n",
    "\n",
    "# to csv\n",
    "acts.to_csv(\"acts_cleaned.csv\", index=False)\n",
    "\n",
    "# get only 40 rows\n",
    "acts = pd.read_csv(\"acts_cleaned.csv\", nrows=40)\n",
    "\n",
    "titles = [\n",
    "    \"Uchwała Senatu Rzeczypospolitej Polskiej z dnia 4 lipca 2024 r. w 35. rocznicę pierwszego posiedzenia odrodzonego Senatu\",\n",
    "    \"Uchwała nr 27/2023 Państwowej Komisji Wyborczej z dnia 29 maja 2023 r. zmieniająca uchwałę w sprawie wzorów urn wyborczych\",\n",
    "    \"Postanowienie Prezydenta Rzeczypospolitej Polskiej z dnia 30 kwietnia 2024 r. nr 112.21.2024 w sprawie mianowania na stopień oficerski generała\",\n",
    "    \"Rozporządzenie Ministra Infrastruktury z dnia 23 grudnia 2022 r. zmieniające rozporządzenie w sprawie warunków eksploatacji lotnisk\",\n",
    "    \"Rozporządzenie Ministra Zdrowia z dnia 8 grudnia 2022 r. w sprawie programu pilotażowego badania stóp dzieci i młodzieży\",\n",
    "    \"Obwieszczenie Marszałka Sejmu Rzeczypospolitej Polskiej z dnia 7 grudnia 2023 r. w sprawie ogłoszenia jednolitego tekstu ustawy - Prawo telekomunikacyjne\",\n",
    "    \"Obwieszczenie Marszałka Sejmu Rzeczypospolitej Polskiej z dnia 1 grudnia 2022 r. w sprawie ogłoszenia jednolitego tekstu ustawy o Polskim Bonie Turystycznym\",\n",
    "    \"Obwieszczenie Marszałka Sejmu Rzeczypospolitej Polskiej z dnia 11 października 2023 r. w sprawie ogłoszenia jednolitego tekstu ustawy o pracy na morzu\",\n",
    "    \"Obwieszczenie Marszałka Sejmu Rzeczypospolitej Polskiej z dnia 4 listopada 2022 r. w sprawie ogłoszenia jednolitego tekstu ustawy o samorządzie gminnym\",\n",
    "    \"Obwieszczenie Marszałka Sejmu Rzeczypospolitej Polskiej z dnia 14 grudnia 2022 r. w sprawie ogłoszenia jednolitego tekstu ustawy o specjalnych strefach ekonomicznych\",\n",
    "    \"Obwieszczenie Marszałka Sejmu Rzeczypospolitej Polskiej z dnia 11 marca 2024 r. w sprawie ogłoszenia jednolitego tekstu ustawy o Inspekcji Ochrony Środowiska\",\n",
    "    \"Obwieszczenie Marszałka Sejmu Rzeczypospolitej Polskiej z dnia 1 grudnia 2022 r. w sprawie ogłoszenia jednolitego tekstu ustawy o Funduszu Kolejowym\",\n",
    "    \"Ustawa z dnia 8 lutego 2023 r. o Planie Strategicznym dla Wspólnej Polityki Rolnej na lata 2023-2027\",\n",
    "    \"Obwieszczenie Marszałka Sejmu Rzeczypospolitej Polskiej z dnia 16 listopada 2022 r. w sprawie ogłoszenia jednolitego tekstu ustawy o partnerstwie publiczno-prywatnym\",\n",
    "    \"Rozporządzenie Ministra Zdrowia z dnia 5 stycznia 2023 r. zmieniające rozporządzenie w sprawie świadczeń gwarantowanych z zakresu podstawowej opieki zdrowotnej\",\n",
    "    \"Obwieszczenie Marszałka Sejmu Rzeczypospolitej Polskiej z dnia 11 marca 2024 r. w sprawie ogłoszenia jednolitego tekstu ustawy o przeciwdziałaniu przemocy domowej\",\n",
    "    \"Rozporządzenie Ministra Infrastruktury z dnia 23 grudnia 2022 r. zmieniające rozporządzenie w sprawie klasyfikacji lotnisk i rejestru lotnisk\",\n",
    "    \"Postanowienie Prezydenta Rzeczypospolitej Polskiej z dnia 27 kwietnia 2023 r. nr 110.36.2023 w sprawie odwołania Ambasadora Rzeczypospolitej Polskiej\",\n",
    "    \"Postanowienie Prezydenta Rzeczypospolitej Polskiej z dnia 27 kwietnia 2023 r. nr 110.38.2023 w sprawie odwołania Ambasadora Rzeczypospolitej Polskiej\",\n",
    "    \"Obwieszczenie Marszałka Sejmu Rzeczypospolitej Polskiej z dnia 16 stycznia 2024 r. w sprawie ogłoszenia jednolitego tekstu ustawy o nadzorze nad rynkiem finansowym\"\n",
    "]\n",
    "\n",
    "cleaned_titles = [clean_title(t) for t in titles]\n",
    "# there is only title column in the csv file\n",
    "# documents = acts[\"title\"].tolist() \n",
    "documents = cleaned_titles\n",
    "print(len(documents))\n",
    "print(documents[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "def find_common_substrings(df, min_length=20, min_occurrences=10):\n",
    "    substring_counts = defaultdict(int)\n",
    "    # Clean and prepare titles\n",
    "    titles = df['title'].str.strip().tolist()\n",
    "    total_titles = len(titles)\n",
    "    \n",
    "    # First, find all \"Rozporządzenie/Obwieszczenie X z dnia\" patterns\n",
    "    skip_pattern = re.compile(r'^(?:Rozporządzenie|Obwieszczenie)\\s+.*?\\s+z\\s+dnia')\n",
    "    \n",
    "    print(f\"Analyzing substrings in {total_titles} documents...\")\n",
    "    for title in tqdm(titles):\n",
    "        # Skip administrative part of the title\n",
    "        skip_match = skip_pattern.match(title)\n",
    "        if skip_match:\n",
    "            start_idx = skip_match.end()\n",
    "            title = title[start_idx:]\n",
    "        \n",
    "        # Get all possible substrings of meaningful length\n",
    "        words = title.split()\n",
    "        for i in range(len(words)):\n",
    "            for j in range(i + 1, len(words) + 1):\n",
    "                substring = ' '.join(words[i:j])\n",
    "                if len(substring) >= min_length:\n",
    "                    substring_counts[substring] += 1\n",
    "\n",
    "    # Filter by minimum occurrences and create DataFrame\n",
    "    common_substrings = [\n",
    "        (substr, count, len(substr), round(count/total_titles * 100, 2))\n",
    "        for substr, count in substring_counts.items()\n",
    "        if count >= min_occurrences\n",
    "    ]\n",
    "    \n",
    "    # Create DataFrame and sort primarily by occurrences\n",
    "    result_df = pd.DataFrame(\n",
    "        common_substrings,\n",
    "        columns=['substring', 'occurrences', 'length', 'percentage']\n",
    "    )\n",
    "    \n",
    "    # Sort by occurrences (descending) and then by length (descending)\n",
    "    result_df = result_df.sort_values(\n",
    "        by=['occurrences', 'length'],\n",
    "        ascending=[False, False]\n",
    "    ).reset_index(drop=True)\n",
    "    \n",
    "    return result_df, total_titles\n",
    "\n",
    "def analyze_titles(csv_path, min_length=20, min_occurrences=5):\n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(csv_path)\n",
    "    \n",
    "    # Find common substrings\n",
    "    common_substrings_df, total_docs = find_common_substrings(\n",
    "        df,\n",
    "        min_length=min_length,\n",
    "        min_occurrences=min_occurrences\n",
    "    )\n",
    "    \n",
    "    pd.set_option('display.max_colwidth', None)\n",
    "    print(f\"\\nAnalyzed {total_docs} documents\")\n",
    "    print(f\"Found {len(common_substrings_df)} common substrings\")\n",
    "    print(\"\\nMost common substrings (sorted by number of occurrences):\")\n",
    "    \n",
    "    # Format the output for better readability\n",
    "    for idx, row in common_substrings_df.head(20).iterrows():\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(f\"#{idx + 1}: Occurs in {row['occurrences']} documents ({row['percentage']}%)\")\n",
    "        print(f\"Length: {row['length']} characters\")\n",
    "        print(f\"Substring: {row['substring']}\")\n",
    "    \n",
    "    # Summary statistics\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"\\nOccurrence Statistics:\")\n",
    "    print(f\"Most frequent: {common_substrings_df['occurrences'].max()} occurrences\")\n",
    "    print(f\"Median occurrences: {common_substrings_df['occurrences'].median()}\")\n",
    "    print(f\"Mean occurrences: {common_substrings_df['occurrences'].mean():.2f}\")\n",
    "    \n",
    "    return common_substrings_df\n",
    "\n",
    "# Usage:\n",
    "# results_df = analyze_titles('Acts.csv', min_length=20, min_occurrences=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_titles('acts_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "import os\n",
    "from pathlib import Path\n",
    "from vertexai.language_models import TextEmbeddingInput, TextEmbeddingModel\n",
    "import vertexai\n",
    "\n",
    "credentials_path = Path().cwd() / \"sejm-stats-439117-39efc9d2f8b8.json\"\n",
    "print(credentials_path)\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = str(credentials_path)\n",
    "\n",
    "\n",
    "vertexai.init(project=\"sejm-stats-439117\")\n",
    "\n",
    "\n",
    "\n",
    "def embed_text(texts: list) -> list[list[float]]:\n",
    "    dimensionality = 512\n",
    "    task = \"RETRIEVAL_DOCUMENT\"\n",
    "\n",
    "\n",
    "    model = TextEmbeddingModel.from_pretrained(\"text-multilingual-embedding-002\")\n",
    "\n",
    "\n",
    "    inputs = [TextEmbeddingInput(text, task) for text in texts]\n",
    "\n",
    "\n",
    "    kwargs = dict(output_dimensionality=dimensionality) if dimensionality else {}\n",
    "\n",
    "\n",
    "    embeddings = model.get_embeddings(inputs, **kwargs)\n",
    "\n",
    "    return [embedding.values for embedding in embeddings]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "embeddings = embed_text(documents)\n",
    "print(len(embeddings[0]))\n",
    "embeddings = np.array(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "em_df =pd.read_csv(\"embeded.csv\")\n",
    "em_df\n",
    "titles= em_df[\"title\"]\n",
    "def string_to_array(embedding_str):\n",
    "    # Convert string representation of list to actual list\n",
    "    try:\n",
    "        # Remove any whitespace and convert to list\n",
    "        embedding_list = ast.literal_eval(embedding_str)\n",
    "        return np.array(embedding_list)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "# Convert embeddings to numpy arrays\n",
    "embeddings = em_df[\"embedding\"].apply(string_to_array)\n",
    "embeddings =  np.vstack(embeddings.to_numpy())\n",
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = \"specjalnych strefach ekonomicznychna\"\n",
    "test = \"Obwieszczenie Ministra Sprawiedliwości z dnia 11 października 2024 r. w sprawie ogłoszenia jednolitego tekstu rozporządzenia Ministra Sprawiedliwości w sprawie organizacji i przebiegu aplikacji notarialnej\"\n",
    "test = \"organizacji i przebiegu aplikacji notarialnej\"\n",
    "phrase_embedding = embed_text([test])\n",
    "# phrase_embedding = np.array(phrase_embedding, dtype=np.float64)\n",
    "phrase_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "similarities = cosine_similarity(phrase_embedding, embeddings)\n",
    "\n",
    "# Get the indices of the top 5 most similar documents\n",
    "top_5_indices = similarities[0].argsort()[-5:][::-1]\n",
    "\n",
    "# Print the top 5 most similar documents and their similarity scores\n",
    "for index in top_5_indices:\n",
    "    print(titles[index])\n",
    "    print(similarities[0][index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
